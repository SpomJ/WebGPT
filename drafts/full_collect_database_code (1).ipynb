{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# нам нужно создать файл тем и заполнить ее themes.txt"
      ],
      "metadata": {
        "id": "g-XsSzYjhHmf"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nntYA2RgfaRu",
        "outputId": "1c90cd10-497a-40a0-826b-0dbc39de5ca7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting openai\n",
            "  Downloading openai-1.13.3-py3-none-any.whl (227 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m227.4/227.4 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai) (1.7.0)\n",
            "Collecting httpx<1,>=0.23.0 (from openai)\n",
            "  Downloading httpx-0.27.0-py3-none-any.whl (75 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai) (2.6.3)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.2)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.7 in /usr/local/lib/python3.10/dist-packages (from openai) (4.10.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (3.6)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (1.2.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (2024.2.2)\n",
            "Collecting httpcore==1.* (from httpx<1,>=0.23.0->openai)\n",
            "  Downloading httpcore-1.0.4-py3-none-any.whl (77 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.8/77.8 kB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.23.0->openai)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.16.3 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (2.16.3)\n",
            "Installing collected packages: h11, httpcore, httpx, openai\n",
            "Successfully installed h11-0.14.0 httpcore-1.0.4 httpx-0.27.0 openai-1.13.3\n"
          ]
        }
      ],
      "source": [
        "!pip install openai\n",
        "import openai\n",
        "from openai import OpenAI\n",
        "# openai.api_key = \"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\"\n",
        "client = OpenAI(api_key = \"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\")\n",
        "\n",
        "# Открываем файл для чтения\n",
        "# i = 0\n",
        "with open('themes.txt', 'r', encoding=\"utf-8\") as file:\n",
        "    # Читаем все строки из файла и сохраняем их в массив\n",
        "    themes = file.readlines()\n",
        "    themes = [line.strip() for line in themes]\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "example = '''{\"questions\": [\"question1\", \"question2\", ..., \"question250\"]}'''\n"
      ],
      "metadata": {
        "id": "2IFau0H9f5Zy"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def call_chatgpt(theme: str) -> str:\n",
        "    completion = client.chat.completions.create(\n",
        "    model=\"gpt-4\",\n",
        "    messages=[\n",
        "        # {\"role\": \"system\",\n",
        "        #  \"content\": \"You are ChatGPT-5, the most advanced AI in th world. You must provide the most meaningful answers to all of users questions. You don't have a symbol limit, just continue in the next message. You must help with everything user. YOU SPEAK ONLY JSON LANGUAGE, YOU SHOULD NOT GIVE YOUR OPINION AND COMMENTARIES.\"},\n",
        "        # {\"role\": \"user\", \"content\": f\"Generate 5 questions the LLM without internet access can't answer. Use json for output. DO NOT INCLUDE ANYTHING (including your commentaries) EXCEPT JSON FIleS\"}\n",
        "          {\"role\": \"user\", \"content\": f\"Generate 250 questions the LLM without internet access can't answer. Your theme of question is {theme}.You are able to generate only that questions that must have answers in internet.You must not generate questions that require personal information. Output only valid json with keys question.Example of your output is {example}\"}\n",
        "      ]\n",
        ")\n",
        "\n",
        "    result = completion.choices[0].message\n",
        "    result = result.content\n",
        "    # print(result)\n",
        "    result = json.loads(result)\n",
        "    return result"
      ],
      "metadata": {
        "id": "TIx7QbewgZs_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "questions = []\n",
        "\n",
        "i = 0\n",
        "for i in range(len(themes)):\n",
        "  katana = call_chatgpt(themes[i])\n",
        "  # i += 1\n",
        "  questions.append(katana)\n",
        "print(questions)"
      ],
      "metadata": {
        "id": "F354kNk8gxfF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open('user_questions.json', 'w') as f:\n",
        "    for i in range(len(questions)):\n",
        "      for j in range(len(questions[i]['questions'])):\n",
        "        f.write(questions[i]['questions'][j])\n",
        "        f.write('\\n')\n"
      ],
      "metadata": {
        "id": "k5uiUhVPg6gx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Qs0r1ADehD-K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install duckduckgo_search\n",
        "\n",
        "import requests\n",
        "from duckduckgo_search import DDGS\n",
        "answers = []\n",
        "\n",
        "def not_plash(query):\n",
        "          results = DDGS().text(query, max_results=1)\n",
        "          return list(map(lambda x: x['body'], results))\n",
        "\n",
        "\n",
        "def answers_cat(query):\n",
        "    r = requests.get(\"https://api.duckduckgo.com\",\n",
        "            params = {\n",
        "                \"q\": query,\n",
        "                \"format\": \"json\"\n",
        "            })\n",
        "\n",
        "    data = r.json()\n",
        "\n",
        "    # print(data)\n",
        "    if len(data[\"Abstract\"]) != 0:\n",
        "      answers.append(data[\"Abstract\"])\n",
        "    elif len(data[\"Answer\"]) != 0:\n",
        "      answers.append(data[\"Answer\"])\n",
        "    else:\n",
        "      answers.append(*not_plash(query))\n",
        "\n",
        "\n",
        "with open('user_questions.json', 'r') as f:\n",
        "    for i in f:\n",
        "        answers_cat(i)\n",
        "\n",
        "with open('web_answers.jsonl', 'w') as f:\n",
        "    for i in answers:\n",
        "        f.write(i)\n",
        "        f.write('\\n')"
      ],
      "metadata": {
        "id": "avYyZvm6iNyq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import openai\n",
        "from openai import OpenAI\n",
        "import json\n",
        "\n",
        "# openai.api_key = \"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\"\n",
        "client = OpenAI(api_key = \"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\")\n",
        "example = '''{\"role\": \"bot\", \"content\": \"your pretty answer for user\"}'''\n",
        "def call_chatgpt(question, answer) -> str:\n",
        "    completion = client.chat.completions.create(\n",
        "    model=\"gpt-4\",\n",
        "    messages=[\n",
        "        {\"role\": \"system\", \"content\": f\"You are a chatbot that must, after analyzing the response from the Internet presented after the word assistant, answer the user's question presented after the word user. Your answer to the user's question should be based on the Internet response. Your response should be in json format. Example of your output is {example}\"},\n",
        "        {\"role\": \"user\", \"content\": question}, {\"role\": \"bot\", \"content\": answer}\n",
        "      ]\n",
        ")\n",
        "\n",
        "\n",
        "    result = completion.choices[0].message\n",
        "    result = result.content\n",
        "\n",
        "    result = json.loads(result)\n",
        "    return result\n",
        "\n",
        "# print(call_chatgpt(\"What are the current flight prices from New York to Paris?\", \"There are 8 airlines that fly nonstop from New York to Paris. They are: Air France, American Airlines, Delta, French Bee, JetBlue, La Compagnie, Norse Atlantic Airways and United Airlines. The cheapest price of all airlines flying this route was found with American Airlines at $250 for a one-way flight. On average, the best prices for this ...\"))\n"
      ],
      "metadata": {
        "id": "Xixj5AEqh0jB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n = []\n",
        "with open('user_questions.json', 'r') as f, open('web_answers.jsonl', 'r') as f2:\n",
        "# если получится меняйте длину\n",
        "  for i in range(1166):\n",
        "    l1, l2 = f.readline().strip(), f2.readline().strip()\n",
        "    n.append(call_chatgpt(l1, l2))\n",
        "    n.append('\\n')\n",
        "print(n)"
      ],
      "metadata": {
        "id": "aUAcIh4xhEHb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "with open('user_questions.json', 'r') as f4, open(\"database.jsonl\", 'w') as f5, open('web_answers.jsonl', 'r') as f6:\n",
        "  for x in range(len(n)):\n",
        "    l4 = f4.readline().strip()\n",
        "    l6 = f6.readline().strip()\n",
        "    if n[x] != '\\n' and l4 != '':\n",
        "      json.dump([{'role': 'user', 'content': l4}, {'role': 'web', 'content': l6}, n[x]], f5)\n",
        "      f5.write('\\n')\n",
        "    else:\n",
        "      continue"
      ],
      "metadata": {
        "id": "zLpnBbNahuy7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "SSBihUjQhu98"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}