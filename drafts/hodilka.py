# -*- coding: utf-8 -*-
"""Untitled12.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1ptBT0UML1P14Pe2l8EHeU7t10HO6c-hx
"""

# !pip install newspaper3k
from googlesearch import search
from transformers import pipeline, DistilBertForQuestionAnswering, DistilBertTokenizer
import torch
import newspaper

# Function to get main text using newspaper3k
def extract_main_text(url):
    article = newspaper.Article(url)
    article.download()
    article.parse()
    return article.text

# User input
user_prompt = input("Ask me something: ")

# Question-Answering using distilbert-base-cased-distilled-squad
model_name = "distilbert-base-cased-distilled-squad"
tokenizer = DistilBertTokenizer.from_pretrained(model_name)
model = DistilBertForQuestionAnswering.from_pretrained(model_name)

# Web search using googlesearch library
search_results = list(search(user_prompt, num=5, stop=5))  # Get top 5 results
if not search_results:
    print("No search results found.")
    exit()

for result_url in search_results:
    print(f"\nChecking result from {result_url}")

    # Get content from the web page using newspaper3k
    context = extract_main_text(result_url)

    # Truncate context to fit within the model's maximum sequence length
    max_seq_length = 512 - len(tokenizer.encode(user_prompt, add_special_tokens=True))
    context = context[:max_seq_length]

    inputs = tokenizer(user_prompt, context, return_tensors="pt", truncation=True)
    start_positions, end_positions = model(**inputs).values()

    start_index = torch.argmax(start_positions)
    end_index = torch.argmax(end_positions) + 1

    answer = tokenizer.decode(inputs["input_ids"][0][start_index:end_index])
    print(f"Answer: {answer}")

